{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "import keras_tuner as kt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from itertools import product\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from random import choice, sample\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, GlobalMaxPool2D, GlobalAvgPool2D, Conv1D, MaxPool1D, Concatenate, Add, Lambda, Multiply, Dropout, Subtract\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image as image_p\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from scipy import stats\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_train_data = pd.read_csv('/home/roman/Work/kinship/train_ds.csv')\n",
    "new_train_data = pd.read_csv('/home/roman/Work/kinship/train2.csv')\n",
    "new_new_train_data = pd.read_csv('/home/roman/Work/kinship/train3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment dataset by generating all possible combos of known kin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumes images in same folder = same person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_set = set()\n",
    "non_relationship_set = set()\n",
    "relationship_set_2 = set()\n",
    "\n",
    "folder_to_images_map = {}\n",
    "all_people_folders = set()\n",
    "base_path = '/home/roman/Work/kinship/train/train-faces/'\n",
    "for index, row in existing_train_data.iterrows():\n",
    "    if row['relationship'] == 1.0:\n",
    "        p1_path = row['p1'].split('/')\n",
    "        p2_path = row['p2'].split('/')\n",
    "        p1_rel_path = p1_path[0] + '/' + p1_path[1]\n",
    "        p2_rel_path = p2_path[0] + '/' + p2_path[1]\n",
    "        \n",
    "        complete_p1_path = os.path.join(base_path, p1_rel_path)\n",
    "        complete_p2_path = os.path.join(base_path, p2_rel_path)\n",
    "        \n",
    "        # Maintain sets for people-folders and known positive relationships\n",
    "        \n",
    "        relationship_set.add((complete_p1_path, complete_p2_path))\n",
    "        relationship_set.add((complete_p2_path, complete_p1_path))\n",
    "        relationship_set_2.add((p1_path[0], p2_path[0]))\n",
    "        relationship_set_2.add((p2_path[0], p1_path[0]))\n",
    "        all_people_folders.add(complete_p1_path)\n",
    "        all_people_folders.add(complete_p2_path)\n",
    "        \n",
    "        # Create mapping between folder names and their image files that ar econtained\n",
    "        folder_to_images_map[complete_p1_path] = set()\n",
    "        folder_to_images_map[complete_p2_path] = set()\n",
    "        \n",
    "        for root, dirs, files in os.walk(complete_p1_path, topdown=False):\n",
    "            for name in files:\n",
    "                folder_to_images_map[complete_p1_path].add(os.path.join(complete_p1_path, name))\n",
    "        \n",
    "        for root, dirs, files in os.walk(complete_p2_path, topdown=False):\n",
    "            for name in files:\n",
    "                folder_to_images_map[complete_p2_path].add(os.path.join(complete_p2_path, name))\n",
    "        \n",
    "for index, row in new_train_data.iterrows():\n",
    "    if row['relationship'] == 1:\n",
    "        p1_path = row['p1'].split('/')\n",
    "        p2_path = row['p2'].split('/')\n",
    "        p1_rel_path = p1_path[0] + '/' + p1_path[1]\n",
    "        p2_rel_path = p2_path[0] + '/' + p2_path[1]\n",
    "        \n",
    "        complete_p1_path = os.path.join(base_path, p1_rel_path)\n",
    "        complete_p2_path = os.path.join(base_path, p2_rel_path)\n",
    "        \n",
    "        relationship_set.add((complete_p1_path, complete_p2_path))\n",
    "        relationship_set.add((complete_p2_path, complete_p1_path))\n",
    "        relationship_set_2.add((p1_path[0], p2_path[0]))\n",
    "        relationship_set_2.add((p2_path[0], p1_path[0]))\n",
    "        all_people_folders.add(complete_p1_path)\n",
    "        all_people_folders.add(complete_p2_path)\n",
    "        \n",
    "        folder_to_images_map[complete_p1_path] = set()\n",
    "        folder_to_images_map[complete_p2_path] = set()\n",
    "        \n",
    "        for root, dirs, files in os.walk(complete_p1_path, topdown=False):\n",
    "            for name in files:\n",
    "                folder_to_images_map[complete_p1_path].add(os.path.join(complete_p1_path, name))\n",
    "        \n",
    "        for root, dirs, files in os.walk(complete_p2_path, topdown=False):\n",
    "            for name in files:\n",
    "                folder_to_images_map[complete_p2_path].add(os.path.join(complete_p2_path, name))\n",
    "\n",
    "for index, row in new_new_train_data.iterrows():\n",
    "    # print(new_new_train_data)\n",
    "    if row['relationship'] == 1:\n",
    "        p1_path = row['p1'].split('/')\n",
    "        p2_path = row['p2'].split('/')\n",
    "        p1_rel_path = p1_path[0] + '/' + p1_path[1]\n",
    "        p2_rel_path = p2_path[0] + '/' + p2_path[1]\n",
    "        \n",
    "        complete_p1_path = os.path.join(base_path, p1_rel_path)\n",
    "        complete_p2_path = os.path.join(base_path, p2_rel_path)\n",
    "        \n",
    "        relationship_set.add((complete_p1_path, complete_p2_path))\n",
    "        relationship_set.add((complete_p2_path, complete_p1_path))\n",
    "        relationship_set_2.add((p1_path[0], p2_path[0]))\n",
    "        relationship_set_2.add((p2_path[0], p1_path[0]))\n",
    "        all_people_folders.add(complete_p1_path)\n",
    "        all_people_folders.add(complete_p2_path)\n",
    "        \n",
    "        folder_to_images_map[complete_p1_path] = set()\n",
    "        folder_to_images_map[complete_p2_path] = set()\n",
    "        \n",
    "        for root, dirs, files in os.walk(complete_p1_path, topdown=False):\n",
    "            for name in files:\n",
    "                folder_to_images_map[complete_p1_path].add(os.path.join(complete_p1_path, name))\n",
    "        \n",
    "        for root, dirs, files in os.walk(complete_p2_path, topdown=False):\n",
    "            for name in files:\n",
    "                folder_to_images_map[complete_p2_path].add(os.path.join(complete_p2_path, name))\n",
    "                \n",
    "# create all possible combos of pairings\n",
    "for a, b in product(list(all_people_folders), list(all_people_folders)):\n",
    "    candidate_pair = (a,b)\n",
    "    a_person_id = a.split('/')[7]\n",
    "    b_person_id = b.split('/')[7]\n",
    "    if candidate_pair not in relationship_set and a_person_id!=b_person_id:\n",
    "        non_relationship_set.add(candidate_pair)\n",
    "        \n",
    "for a, b in product(list(all_people_folders), list(all_people_folders)):\n",
    "    candidate_pair = (a,b)\n",
    "    a_person_id = a.split('/')[7]\n",
    "    b_person_id = b.split('/')[7]\n",
    "    person_candidate_pair = (a_person_id, b_person_id)\n",
    "    if candidate_pair not in non_relationship_set and a_person_id!=b_person_id and person_candidate_pair in relationship_set_2:\n",
    "        relationship_set.add(candidate_pair)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Val generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perturbs half the images and leaves the rest alone. Color transfer non-functional, so we're only using affine image transormations of rotation, resize, and translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path1, path2, perturb=False, color_transfer_bool=False):\n",
    "    img1 = image_p.load_img(path1, target_size=(224, 224))\n",
    "    img1 = np.array(img1).astype(np.float)\n",
    "    img2 = image_p.load_img(path2, target_size=(224, 224))\n",
    "    img2 = np.array(img2).astype(np.float)\n",
    "    return preprocess_input(img1, version=2), preprocess_input(img2, version=2)\n",
    "\n",
    "def gen(relationship_tuples, non_relationship_tuples, person_to_images_map, batch_size=16):\n",
    "    while True:\n",
    "        \n",
    "        # color transfer and perturb\n",
    "        relationship_batch_tuples = sample(relationship_tuples, batch_size//2)\n",
    "        non_relationship_batch_tuples = sample(non_relationship_tuples, batch_size//2)\n",
    "        \n",
    "        incomplete_path_batch_tuples = relationship_batch_tuples + non_relationship_batch_tuples\n",
    "        \n",
    "        batch_tuples = [(sample(person_to_images_map[p1], 1)[0], sample(person_to_images_map[p2], 1)[0]) for p1, p2 in incomplete_path_batch_tuples]\n",
    "            \n",
    "        labels = batch_size//2*[1] + batch_size//2*[0]\n",
    "        \n",
    "        # print(batch_tuples)\n",
    "        # print(labels)\n",
    "        \n",
    "        processed_batch_image_tuples = [read_img(img1_path, img2_path, perturb=False, color_transfer_bool=False) for img1_path, img2_path in batch_tuples]\n",
    "        unzipped_processed_batch_images = list(zip(*processed_batch_image_tuples))\n",
    "        \n",
    "        X1 = np.array(list(unzipped_processed_batch_images[0]))\n",
    "\n",
    "        X2 = np.array(list(unzipped_processed_batch_images[1]))\n",
    "\n",
    "        yield [X1, X2], np.array(labels)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = gen(relationship_set, non_relationship_set, folder_to_images_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create relationship/nonrelationship data based on set differencing and one person per folder assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_file_path = \"/home/roman/Work/kinship/train_ds.csv\"\n",
    "train_folders_path = \"/home/roman/Work/kinship/train/train-faces/\"\n",
    "\n",
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))\n",
    "\n",
    "def get_random_validation_sets(all_relationships, all_non_relationships, n):\n",
    "\n",
    "    relationship_set =  [] \n",
    "    for validation_set in split(list(all_relationships), n):\n",
    "        relationship_set.append(set(validation_set))\n",
    "    \n",
    "    non_relationship_set =  [] \n",
    "    for validation_set in split(list(all_non_relationships), n):\n",
    "        non_relationship_set.append(set(validation_set))\n",
    "    \n",
    "    return relationship_set, non_relationship_set\n",
    "\n",
    "def get_random_train_val_sets(all_relationships, all_non_relationships, n, person_to_images_map):\n",
    "    generators = []\n",
    "    \n",
    "    relationship_val_sets, non_relationship_val_sets = get_random_validation_sets(all_relationships, all_non_relationships, n)\n",
    "    \n",
    "    for val_relationship_set, val_non_relationship_set in zip(relationship_val_sets, non_relationship_val_sets):\n",
    "        train_relationship_set = all_relationships.difference(val_relationship_set)\n",
    "        train_non_relationship_set = all_non_relationships.difference(val_non_relationship_set)\n",
    "        yield gen(train_relationship_set, train_non_relationship_set, person_to_images_map), gen(val_relationship_set, val_non_relationship_set, person_to_images_map)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_gen = get_random_train_val_sets(relationship_set, non_relationship_set, k_folds, folder_to_images_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_val_sets, non_relationship_val_sets = get_random_validation_sets(relationship_set, non_relationship_set, k_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"validation_sets_perturbed_with_test_{datetime.date.today().strftime('%Y_%m_%d')}.pickle\", 'wb') as f:\n",
    "    pickle.dump((relationship_val_sets, non_relationship_val_sets), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get('val_acc') >= .8:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_on_plateau =  ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.3, patience=2, verbose=1)\n",
    "\n",
    "max_val_acc = CustomCallback()\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=12, min_delta=.0075)\n",
    "\n",
    "log_dir = '/home/roman/Work/kinship/logs'\n",
    "\n",
    "# tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "callbacks_list = [\n",
    "    # max_val_acc, \n",
    "    reduce_on_plateau, \n",
    "    stop_early\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference architecture: https://arxiv.org/abs/2006.00143v2\n",
    "def baseline_model():\n",
    "    input_1 = Input(shape=(224, 224, 3))\n",
    "    input_2 = Input(shape=(224, 224, 3))\n",
    "\n",
    "    base_model = VGGFace(model='resnet50', include_top=False)\n",
    "\n",
    "    for x in base_model.layers[:-3]:\n",
    "        x.trainable = True\n",
    "\n",
    "    x1 = base_model(input_1)\n",
    "    x2 = base_model(input_2)\n",
    "\n",
    "\n",
    "    x1=GlobalMaxPool2D()(x1)\n",
    "    x2=GlobalAvgPool2D()(x2)\n",
    "    \n",
    "    x3 = Subtract()([x1, x2])\n",
    "    x3 = Multiply()([x3, x3])\n",
    "    \n",
    "    x1_ = Multiply()([x1, x1])\n",
    "    x2_ = Multiply()([x2, x2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    \n",
    "    x5 = Multiply()([x1, x2])\n",
    "    \n",
    "    x = Concatenate(axis=-1)([x3, x4, x5])\n",
    "#     x = Dense(512, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.03)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00001))\n",
    "#     model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc'], optimizer=Adam(0.00003))\n",
    "#     model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc'], optimizer=Adam(0.00001))\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vggface_resnet50 (Functional)   (None, None, None, 2 23561152    input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 2048)         0           vggface_resnet50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, 2048)         0           global_max_pooling2d[0][0]       \n",
      "                                                                 global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 2048)         0           global_max_pooling2d[0][0]       \n",
      "                                                                 global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 2048)         0           subtract[0][0]                   \n",
      "                                                                 subtract[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 2048)         0           multiply_1[0][0]                 \n",
      "                                                                 multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 2048)         0           global_max_pooling2d[0][0]       \n",
      "                                                                 global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6144)         0           multiply[0][0]                   \n",
      "                                                                 subtract_1[0][0]                 \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          786560      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,364,353\n",
      "Trainable params: 24,311,233\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vggface_resnet50 (Functional)   (None, None, None, 2 23561152    input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 2048)         0           vggface_resnet50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           vggface_resnet50[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, 2048)         0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, 2048)         0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_max_pooling2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "                                                                 global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 2048)         0           subtract_2[0][0]                 \n",
      "                                                                 subtract_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "subtract_3 (Subtract)           (None, 2048)         0           multiply_5[0][0]                 \n",
      "                                                                 multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 2048)         0           global_max_pooling2d_1[0][0]     \n",
      "                                                                 global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6144)         0           multiply_4[0][0]                 \n",
      "                                                                 subtract_3[0][0]                 \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          786560      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          16512       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            129         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,364,353\n",
      "Trainable params: 24,311,233\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-e024f4f20b08>:12: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  relationship_batch_tuples = sample(relationship_tuples, batch_size//2)\n",
      "<ipython-input-4-e024f4f20b08>:13: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  non_relationship_batch_tuples = sample(non_relationship_tuples, batch_size//2)\n",
      "<ipython-input-4-e024f4f20b08>:17: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  batch_tuples = [(sample(person_to_images_map[p1], 1)[0], sample(person_to_images_map[p2], 1)[0]) for p1, p2 in incomplete_path_batch_tuples]\n",
      "<ipython-input-4-e024f4f20b08>:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  img1 = np.array(img1).astype(np.float)\n",
      "<ipython-input-4-e024f4f20b08>:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  img2 = np.array(img2).astype(np.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "32/32 [==============================] - 59s 2s/step - loss: 5.6584 - acc: 0.5176 - val_loss: 5.2194 - val_acc: 0.5010\n",
      "Epoch 2/16\n",
      "32/32 [==============================] - 46s 1s/step - loss: 3.7803 - acc: 0.4997 - val_loss: 4.3201 - val_acc: 0.4917\n",
      "Epoch 3/16\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5061 - acc: 0.5020"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e527cffaf6bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"pwc_perturbed_more_samples_tes_data_random_validation_ensemble_v3_{i}.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         history = model.fit(\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1131\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1132\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "need_to_train = [1]\n",
    "train_all = True\n",
    "for i, (train_gen, val_gen) in enumerate(train_val_gen):\n",
    "    if i in need_to_train or train_all:\n",
    "        model = baseline_model()\n",
    "        file_path = f\"pwc_perturbed_more_samples_tes_data_random_validation_ensemble_v3_{i}.h5\"\n",
    "        history = model.fit(\n",
    "            train_gen, \n",
    "            use_multiprocessing=False,\n",
    "            validation_data=val_gen, \n",
    "            epochs=16, callbacks=callbacks_list, \n",
    "            steps_per_epoch=32, validation_steps=128\n",
    "        )\n",
    "        model.save(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export predictions for a single model inside ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure class predictions match test set proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img_for_prediction(path):\n",
    "    img = image_p.load_img(path, target_size=(224, 224))\n",
    "    img = np.array(img).astype(np.float)\n",
    "    return preprocess_input(img, version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime \n",
    "submission = pd.read_csv('/home/roman/Work/kinship/test_ds2.csv')\n",
    "prediction_list = []\n",
    "test_path = \"/home/roman/Work/kinship/test2/\"\n",
    "for j in range(k_folds):\n",
    "    print(f'exporting prediction number {j}')\n",
    "    file_path = f\"pwc_perturbed_more_samples_tes_data_random_validation_ensemble_v3_{j}.h5\"\n",
    "    model = load_model(file_path)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(0, len(submission.p1.values), 32):\n",
    "\n",
    "        X1 = submission.p1.values[i:i+32]\n",
    "        X1 = np.array([read_img_for_prediction(test_path + x) for x in X1])\n",
    "\n",
    "        X2 = submission.p2.values[i:i+32]\n",
    "        X2 = np.array([read_img_for_prediction(test_path + x) for x in X2])\n",
    "\n",
    "        pred = model.predict([X1, X2]).ravel().tolist()\n",
    "        predictions += pred\n",
    "        \n",
    "    np.array(predictions)\n",
    "        \n",
    "    prediction_list.append(predictions)\n",
    "    \n",
    "    d = {'index': np.arange(0, len(predictions), 1), 'label': predictions}\n",
    "    submissionfile = pd.DataFrame(data=d)\n",
    "    # Balance prediction class ratio with expected test class ratio\n",
    "    score_for_0 = submissionfile['label'].quantile(0.493333)\n",
    "    preds1 = submissionfile['label'].apply(lambda s: 1 if s>score_for_0 else 0).to_frame('label').reset_index()['label']\n",
    "    submissionfile['label'] = preds1\n",
    "    submissionfile['label'] = submissionfile['label'].astype(int)\n",
    "    submissionfile.to_csv(f\"/home/roman/Work/kinship/pwc_perturbed_more_samples_random_validation_ensemble_v7_{datetime.date.today().strftime('%Y_%m_%d')}_{j}.csv\", index=False)\n",
    "\n",
    "    del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import datetime \n",
    "submission = pd.read_csv('/home/roman/Work/kinship/test_ds2.csv')\n",
    "# prediction_list = []\n",
    "test_path = \"/home/roman/Work/kinship/test2/\"\n",
    "models = glob.glob('./*.h5')\n",
    "for index, model in enumerate(models):\n",
    "    if index > 3:\n",
    "        print(model)\n",
    "        model = load_model(model)\n",
    "\n",
    "        predictions = []\n",
    "        batch_size = 256\n",
    "        for i in range(0, len(submission.p1.values), batch_size):\n",
    "\n",
    "            X1 = submission.p1.values[i:i+batch_size]\n",
    "            X1 = np.array([read_img_for_prediction(test_path + x) for x in X1])\n",
    "\n",
    "            X2 = submission.p2.values[i:i+batch_size]\n",
    "            X2 = np.array([read_img_for_prediction(test_path + x) for x in X2])\n",
    "\n",
    "            pred = model.predict([X1, X2]).ravel().tolist()\n",
    "            predictions += pred\n",
    "\n",
    "        np.array(predictions)\n",
    "\n",
    "        prediction_list.append(predictions)\n",
    "\n",
    "        d = {'index': np.arange(0, len(predictions), 1), 'label': predictions}\n",
    "        submissionfile = pd.DataFrame(data=d)\n",
    "        # Balance prediction class ratio with expected test class ratio\n",
    "        score_for_0 = submissionfile['label'].quantile(0.493333)\n",
    "        preds1 = submissionfile['label'].apply(lambda s: 1 if s>score_for_0 else 0).to_frame('label').reset_index()['label']\n",
    "        submissionfile['label'] = preds1\n",
    "        submissionfile['label'] = submissionfile['label'].astype(int)\n",
    "        submissionfile.to_csv(f\"/home/roman/Work/kinship/pwc_perturbed_more_samples_random_validation_ensemble_v7_{datetime.date.today().strftime('%Y_%m_%d')}_{index}.csv\", index=False)\n",
    "\n",
    "        del model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda x: int(round(x,0))\n",
    "final_predictions = [list(map(func, i)) for i in prediction_list]\n",
    "\n",
    "final_predictions = stats.mode(final_predictions)[0][0]\n",
    "d = {'index': np.arange(0, len(p), 1), 'label': final_predictions}\n",
    "submissionfile = pd.DataFrame(data=d)\n",
    "submissionfile['label'] = submissionfile['label'].astype(int)\n",
    "submissionfile.to_csv(f\"/home/roman/Work/kinship/giant_ensemble_v2_{datetime.date.today().strftime('%Y_%m_%d')}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl3",
   "language": "python",
   "name": "dl3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
