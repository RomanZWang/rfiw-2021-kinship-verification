{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from random import choice, sample\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import ResNet50V2, ResNet101V2, Xception, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, GlobalMaxPool2D, GlobalAvgPool2D, Conv1D, MaxPool1D, Concatenate, Add, Lambda, Multiply, Dropout, Subtract\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(test_cases):\n",
    "    \n",
    "    generator = gen(train, train_person_to_images_map, batch_size=16)\n",
    "    for test_case in test_cases:\n",
    "        print(f'testing {test_case}')\n",
    "        images, labels = next(generator)\n",
    "        image_1 = images['input_1']\n",
    "        test_model = get_model_by_name(test_case)\n",
    "        result = test_model(image_1)\n",
    "        print(result)\n",
    "        \n",
    "def get_model_by_name(model_type):\n",
    "    kwargs = {'include_top': False}\n",
    "    if model_type == \"vgg16\":\n",
    "        return VGGFace(model='vgg16', **kwargs)\n",
    "    elif model_type == \"resnet50\":\n",
    "        return VGGFace(model='resnet50', **kwargs)\n",
    "    elif model_type == \"senet50\":\n",
    "        return VGGFace(model='senet50', **kwargs)\n",
    "    elif model_type == \"Xception\":\n",
    "        return Xception(**kwargs)\n",
    "    elif model_type == \"InceptionV3\":\n",
    "        return InceptionV3(**kwargs)\n",
    "    elif model_type == \"InceptionResNetV2\":\n",
    "        return InceptionResNetV2(**kwargs)\n",
    "    elif model_type == \"MobileNetV2\":\n",
    "        return MobileNetV2(**kwargs)\n",
    "    elif model_type == \"DenseNet121\":\n",
    "        return DenseNet121(**kwargs)\n",
    "    elif model_type == \"DenseNet169\":\n",
    "        return DenseNet169(**kwargs)\n",
    "    elif model_type == \"DenseNet201\":\n",
    "        return DenseNet201(**kwargs)\n",
    "    elif model_type == \"NASNetMobile\":\n",
    "        return NASNetMobile(**kwargs)\n",
    "    elif model_type == \"EfficientNetB0\":\n",
    "        return EfficientNetB0(**kwargs)\n",
    "    elif model_type == \"EfficientNetB1\":\n",
    "        return EfficientNetB1(**kwargs)\n",
    "    elif model_type == \"EfficientNetB2\":\n",
    "        return EfficientNetB2(**kwargs)\n",
    "    elif model_type == \"EfficientNetB3\":\n",
    "        return EfficientNetB3(**kwargs)\n",
    "    elif model_type == \"EfficientNetB4\":\n",
    "        return EfficientNetB4(**kwargs)\n",
    "    elif model_type == \"EfficientNetB5\":\n",
    "        return EfficientNetB5(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_transfer_learning_models = [\n",
    "    \"vgg16\", \n",
    "    \"resnet50\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_train_data = pd.read_csv('/home/roman/Work/kinship/train_ds.csv')\n",
    "new_train_data = pd.read_csv('/home/roman/Work/kinship/train2.csv')\n",
    "new_new_train_data = pd.read_csv('/home/roman/Work/kinship/train3.csv')\n",
    "# new_new_new_train_data = pd.read_csv('/home/roman/Work/kinship/train4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path1, path2, perturb=False, color_transfer_bool=False):\n",
    "    if perturb and color_transfer_bool:\n",
    "#         image1 = cv2.imread(path1)\n",
    "#         image2 = cv2.imread(path2)\n",
    "        \n",
    "        image1 = image_p.load_img(path1, target_size=(224, 224))\n",
    "        image1 = np.array(image1).astype(np.float)\n",
    "        image2 = image_p.load_img(path2, target_size=(224, 224))\n",
    "        image2 = np.array(image2).astype(np.float)\n",
    "        \n",
    "        colored_image2 = color_transfer(image1, image2)\n",
    "        \n",
    "        generated_perturbation_parameters = generate_random_perturbation_parameters()\n",
    "        perturbed_image1 = rotate_resize_translate_image(image1, *generated_perturbation_parameters).astype(np.float)\n",
    "        \n",
    "        generated_perturbation_parameters = generate_random_perturbation_parameters()\n",
    "        perturbed_image2 = rotate_resize_translate_image(colored_image2, *generated_perturbation_parameters).astype(np.float)\n",
    "        \n",
    "#         img1 = image_p.load_img(path1, target_size=(224, 224))\n",
    "#         img1 = np.array(img1).astype(np.float)\n",
    "#         img2 = image_p.load_img(path2, target_size=(224, 224))\n",
    "#         img2 = np.array(img2).astype(np.float)\n",
    "        \n",
    "        # print(preprocess_input(img1, version=2))\n",
    "        # print(preprocess_input(img2, version=2))\n",
    "        \n",
    "        # print(perturbed_image1)\n",
    "        # print(perturbed_image2)\n",
    "        \n",
    "        return preprocess_input(perturbed_image1, version=2), preprocess_input(perturbed_image2, version=2)\n",
    "    elif perturb and not color_transfer_bool:\n",
    "        # image = cv2.imread(path1)\n",
    "        image = image_p.load_img(path1, target_size=(224, 224))\n",
    "        image = np.array(image).astype(np.float)\n",
    "        \n",
    "        generated_perturbation_parameters = generate_random_perturbation_parameters()\n",
    "        perturbed_image1 = rotate_resize_translate_image(image, *generated_perturbation_parameters).astype(np.float)\n",
    "        perturbed_image1 = np.matrix.round(perturbed_image1)\n",
    "        # image = cv2.imread(path2)\n",
    "        image = image_p.load_img(path1, target_size=(224, 224))\n",
    "        image = np.array(image).astype(np.float)\n",
    "        generated_perturbation_parameters = generate_random_perturbation_parameters()\n",
    "        perturbed_image2 = rotate_resize_translate_image(image, *generated_perturbation_parameters).astype(np.float)\n",
    "        perturbed_image2 = np.matrix.round(perturbed_image2)\n",
    "        return preprocess_input(perturbed_image1, version=2), preprocess_input(perturbed_image2, version=2)\n",
    "    elif not perturb and color_transfer_bool:\n",
    "#         image1 = cv2.imread(path1).astype(np.float)\n",
    "#         image2 = cv2.imread(path2).astype(np.float)\n",
    "        \n",
    "        image1 = image_p.load_img(path1, target_size=(224, 224))\n",
    "        image1 = np.array(image1).astype(np.float)\n",
    "        image2 = image_p.load_img(path2, target_size=(224, 224))\n",
    "        image2 = np.array(image2).astype(np.float)\n",
    "        \n",
    "        colored_image2 = color_transfer(image1, image2).astype(np.float)\n",
    "        return preprocess_input(image1, version=2).astype(np.float), preprocess_input(colored_image2, version=2).astype(np.float)\n",
    "    else:\n",
    "        img1 = image_p.load_img(path1, target_size=(224, 224))\n",
    "        img1 = np.array(img1).astype(np.float)\n",
    "        img2 = image_p.load_img(path2, target_size=(224, 224))\n",
    "        img2 = np.array(img2).astype(np.float)\n",
    "        return preprocess_input(img1, version=2), preprocess_input(img2, version=2)\n",
    "    \n",
    "def gen(relationship_tuples, non_relationship_tuples, person_to_images_map, batch_size=16):\n",
    "    while True:\n",
    "        # no color transfer\n",
    "#         relationship_batch_tuples = sample(relationship_tuples, batch_size//2)\n",
    "#         non_relationship_batch_tuples = sample(non_relationship_tuples, batch_size//2)\n",
    "        \n",
    "#         incomplete_path_batch_tuples = relationship_batch_tuples + non_relationship_batch_tuples\n",
    "        \n",
    "#         batch_tuples = [(sample(person_to_images_map[p1], 1)[0], sample(person_to_images_map[p2], 1)[0]) for p1, p2 in incomplete_path_batch_tuples]\n",
    "            \n",
    "#         labels = batch_size//2*[1] + batch_size//2*[0]\n",
    "        \n",
    "#         # print(batch_tuples)\n",
    "#         # print(labels)\n",
    "        \n",
    "#         processed_batch_image_tuples = [read_img(img1_path, img2_path) for img1_path, img2_path in batch_tuples]\n",
    "#         unzipped_processed_batch_images = list(zip(*processed_batch_image_tuples))\n",
    "        \n",
    "#         X1 = np.array(list(unzipped_processed_batch_images[0]))\n",
    "\n",
    "#         X2 = np.array(list(unzipped_processed_batch_images[1]))\n",
    "\n",
    "#         yield [X1, X2], np.array(labels)\n",
    "        \n",
    "        # color transfer and perturb\n",
    "        relationship_batch_tuples = sample(relationship_tuples, batch_size//2)\n",
    "        non_relationship_batch_tuples = sample(non_relationship_tuples, batch_size//2)\n",
    "        \n",
    "        incomplete_path_batch_tuples = relationship_batch_tuples + non_relationship_batch_tuples\n",
    "        \n",
    "        batch_tuples = [(sample(person_to_images_map[p1], 1)[0], sample(person_to_images_map[p2], 1)[0]) for p1, p2 in incomplete_path_batch_tuples]\n",
    "            \n",
    "        labels = batch_size//2*[1] + batch_size//2*[0]\n",
    "        \n",
    "        # print(batch_tuples)\n",
    "        # print(labels)\n",
    "        \n",
    "        processed_batch_image_tuples = [read_img(img1_path, img2_path, perturb=False, color_transfer_bool=False) for img1_path, img2_path in batch_tuples]\n",
    "        unzipped_processed_batch_images = list(zip(*processed_batch_image_tuples))\n",
    "        \n",
    "        X1 = np.array(list(unzipped_processed_batch_images[0]))\n",
    "\n",
    "        X2 = np.array(list(unzipped_processed_batch_images[1]))\n",
    "\n",
    "        yield [X1, X2], np.array(labels)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_set = set()\n",
    "non_relationship_set = set()\n",
    "relationship_set_2 = set()\n",
    "\n",
    "folder_to_images_map = {}\n",
    "all_people_folders = set()\n",
    "base_path = '/home/roman/Work/kinship/train/train-faces/'\n",
    "for index, row in existing_train_data.iterrows():\n",
    "    if row['relationship'] == 1.0:\n",
    "        p1_path = row['p1'].split('/')\n",
    "        p2_path = row['p2'].split('/')\n",
    "        p1_rel_path = p1_path[0] + '/' + p1_path[1]\n",
    "        p2_rel_path = p2_path[0] + '/' + p2_path[1]\n",
    "        \n",
    "        complete_p1_path = os.path.join(base_path, p1_rel_path)\n",
    "        complete_p2_path = os.path.join(base_path, p2_rel_path)\n",
    "        \n",
    "        # Maintain sets for people-folders and known positive relationships\n",
    "        \n",
    "        relationship_set.add((complete_p1_path, complete_p2_path))\n",
    "        relationship_set.add((complete_p2_path, complete_p1_path))\n",
    "        relationship_set_2.add((p1_path[0], p2_path[0]))\n",
    "        relationship_set_2.add((p2_path[0], p1_path[0]))\n",
    "        all_people_folders.add(complete_p1_path)\n",
    "        all_people_folders.add(complete_p2_path)\n",
    "        \n",
    "        # Create mapping between folder names and their image files that ar econtained\n",
    "        folder_to_images_map[complete_p1_path] = set()\n",
    "        folder_to_images_map[complete_p2_path] = set()\n",
    "        \n",
    "        for root, dirs, files in os.walk(complete_p1_path, topdown=False):\n",
    "            for name in files:\n",
    "                folder_to_images_map[complete_p1_path].add(os.path.join(complete_p1_path, name))\n",
    "        \n",
    "        for root, dirs, files in os.walk(complete_p2_path, topdown=False):\n",
    "            for name in files:\n",
    "                folder_to_images_map[complete_p2_path].add(os.path.join(complete_p2_path, name))\n",
    "        \n",
    "for index, row in new_train_data.iterrows():\n",
    "    if row['relationship'] == 1:\n",
    "        p1_path = row['p1'].split('/')\n",
    "        p2_path = row['p2'].split('/')\n",
    "        p1_rel_path = p1_path[0] + '/' + p1_path[1]\n",
    "        p2_rel_path = p2_path[0] + '/' + p2_path[1]\n",
    "        \n",
    "        complete_p1_path = os.path.join(base_path, p1_rel_path)\n",
    "        complete_p2_path = os.path.join(base_path, p2_rel_path)\n",
    "        \n",
    "        relationship_set.add((complete_p1_path, complete_p2_path))\n",
    "        relationship_set.add((complete_p2_path, complete_p1_path))\n",
    "        relationship_set_2.add((p1_path[0], p2_path[0]))\n",
    "        relationship_set_2.add((p2_path[0], p1_path[0]))\n",
    "        all_people_folders.add(complete_p1_path)\n",
    "        all_people_folders.add(complete_p2_path)\n",
    "        \n",
    "        folder_to_images_map[complete_p1_path] = set()\n",
    "        folder_to_images_map[complete_p2_path] = set()\n",
    "        \n",
    "        for root, dirs, files in os.walk(complete_p1_path, topdown=False):\n",
    "            for name in files:\n",
    "                folder_to_images_map[complete_p1_path].add(os.path.join(complete_p1_path, name))\n",
    "        \n",
    "        for root, dirs, files in os.walk(complete_p2_path, topdown=False):\n",
    "            for name in files:\n",
    "                folder_to_images_map[complete_p2_path].add(os.path.join(complete_p2_path, name))\n",
    "\n",
    "for index, row in new_new_train_data.iterrows():\n",
    "    # print(new_new_train_data)\n",
    "    if row['relationship'] == 1:\n",
    "        p1_path = row['p1'].split('/')\n",
    "        p2_path = row['p2'].split('/')\n",
    "        p1_rel_path = p1_path[0] + '/' + p1_path[1]\n",
    "        p2_rel_path = p2_path[0] + '/' + p2_path[1]\n",
    "        \n",
    "        complete_p1_path = os.path.join(base_path, p1_rel_path)\n",
    "        complete_p2_path = os.path.join(base_path, p2_rel_path)\n",
    "        \n",
    "        relationship_set.add((complete_p1_path, complete_p2_path))\n",
    "        relationship_set.add((complete_p2_path, complete_p1_path))\n",
    "        relationship_set_2.add((p1_path[0], p2_path[0]))\n",
    "        relationship_set_2.add((p2_path[0], p1_path[0]))\n",
    "        all_people_folders.add(complete_p1_path)\n",
    "        all_people_folders.add(complete_p2_path)\n",
    "        \n",
    "        folder_to_images_map[complete_p1_path] = set()\n",
    "        folder_to_images_map[complete_p2_path] = set()\n",
    "        \n",
    "        for root, dirs, files in os.walk(complete_p1_path, topdown=False):\n",
    "            for name in files:\n",
    "                folder_to_images_map[complete_p1_path].add(os.path.join(complete_p1_path, name))\n",
    "        \n",
    "        for root, dirs, files in os.walk(complete_p2_path, topdown=False):\n",
    "            for name in files:\n",
    "                folder_to_images_map[complete_p2_path].add(os.path.join(complete_p2_path, name))\n",
    "                \n",
    "# create all possible combos of pairings\n",
    "for a, b in product(list(all_people_folders), list(all_people_folders)):\n",
    "    candidate_pair = (a,b)\n",
    "    a_person_id = a.split('/')[7]\n",
    "    b_person_id = b.split('/')[7]\n",
    "    if candidate_pair not in relationship_set and a_person_id!=b_person_id:\n",
    "        non_relationship_set.add(candidate_pair)\n",
    "        \n",
    "for a, b in product(list(all_people_folders), list(all_people_folders)):\n",
    "    candidate_pair = (a,b)\n",
    "    a_person_id = a.split('/')[7]\n",
    "    b_person_id = b.split('/')[7]\n",
    "    person_candidate_pair = (a_person_id, b_person_id)\n",
    "    if candidate_pair not in non_relationship_set and person_candidate_pair in relationship_set_2:\n",
    "        relationship_set.add(candidate_pair)\n",
    "        \n",
    "# for index, row in new_new_new_train_data.iterrows():\n",
    "#     p1_rel_path = row['p1']\n",
    "#     p2_rel_path = row['p2']\n",
    "\n",
    "#     complete_p1_path = os.path.join(base_path, p1_rel_path)\n",
    "#     complete_p2_path = os.path.join(base_path, p2_rel_path)\n",
    "\n",
    "#     relationship_set.add((complete_p1_path, complete_p2_path))\n",
    "#     relationship_set.add((complete_p2_path, complete_p1_path))\n",
    "\n",
    "#     all_people_folders.add(complete_p1_path)\n",
    "#     all_people_folders.add(complete_p2_path)\n",
    "\n",
    "#     folder_to_images_map[complete_p1_path] = set()\n",
    "#     folder_to_images_map[complete_p2_path] = set()\n",
    "\n",
    "\n",
    "#     folder_to_images_map[complete_p1_path].add(complete_p2_path)\n",
    "#     folder_to_images_map[complete_p2_path].add(complete_p2_path)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_file_path = \"/home/roman/Work/kinship/train_ds.csv\"\n",
    "train_folders_path = \"/home/roman/Work/kinship/train/train-faces/\"\n",
    "\n",
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i*k+min(i, m):(i+1)*k+min(i+1, m)] for i in range(n))\n",
    "\n",
    "def get_random_validation_sets(all_relationships, all_non_relationships, n):\n",
    "\n",
    "    relationship_set =  [] \n",
    "    for validation_set in split(list(all_relationships), n):\n",
    "        relationship_set.append(set(validation_set))\n",
    "    \n",
    "    non_relationship_set =  [] \n",
    "    for validation_set in split(list(all_non_relationships), n):\n",
    "        non_relationship_set.append(set(validation_set))\n",
    "    \n",
    "    return relationship_set, non_relationship_set\n",
    "\n",
    "def get_random_train_val_sets(all_relationships, all_non_relationships, n, person_to_images_map):\n",
    "    generators = []\n",
    "    \n",
    "    relationship_val_sets, non_relationship_val_sets = get_random_validation_sets(all_relationships, all_non_relationships, n)\n",
    "    \n",
    "    for val_relationship_set, val_non_relationship_set in zip(relationship_val_sets, non_relationship_val_sets):\n",
    "        train_relationship_set = all_relationships.difference(val_relationship_set)\n",
    "        train_non_relationship_set = all_non_relationships.difference(val_non_relationship_set)\n",
    "        yield gen(train_relationship_set, train_non_relationship_set, person_to_images_map), gen(val_relationship_set, val_non_relationship_set, person_to_images_map)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 5\n",
    "train_val_gen = get_random_train_val_sets(relationship_set, non_relationship_set, k_folds, folder_to_images_map)\n",
    "relationship_val_sets, non_relationship_val_sets = get_random_validation_sets(relationship_set, non_relationship_set, k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# import pickle\n",
    "# # with open(f\"validation_sets_kt_{datetime.date.today().strftime('%Y_%m_%d')}.pickle\", 'wb') as f:\n",
    "# #     pickle.dump(validation_sets, f)\n",
    "# with open(f\"validation_sets_kt_{datetime.date.today().strftime('%Y_%m_%d')}.pickle\", 'rb') as f:\n",
    "#      validation_sets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get('val_accuracy') >= .8:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"/home/roman/Work/kinship/vgg_face_ak.h5\"\n",
    "\n",
    "# checkpoint = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_accuracy\", mode=\"max\", factor=0.1, patience=1, verbose=1)\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)\n",
    "\n",
    "log_dir = '/home/roman/Work/kinship/logs'\n",
    "\n",
    "max_val_acc = CustomCallback()\n",
    "\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# callbacks_list = [checkpoint, reduce_on_plateau]\n",
    "callbacks_list = [tensorboard_callback, max_val_acc, reduce_on_plateau, stop_early]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    input1 = tf.keras.Input(shape=(224, 224, 3))\n",
    "    input2 = tf.keras.Input(shape=(224, 224, 3))\n",
    "    \n",
    "    base_model_string = hp.Choice('transfer_learning_model', list_of_transfer_learning_models, default='resnet50')\n",
    "    base_model = get_model_by_name(base_model_string)\n",
    "\n",
    "    for x in base_model.layers[:-3]:\n",
    "        x.trainable = True\n",
    "    x1 = base_model(input1)\n",
    "    x2 = base_model(input2)\n",
    "\n",
    "    x1_avg = GlobalAvgPool2D()(x1)\n",
    "    x2_avg = GlobalAvgPool2D()(x2)\n",
    "\n",
    "    x1_max = GlobalMaxPool2D()(x1)\n",
    "    x2_max = GlobalMaxPool2D()(x2)\n",
    "    \n",
    "    lambda_outputs = []\n",
    "    \n",
    "    for i in range(hp.Int(\"number_of_lambda_layers\", 1, 4, default=2)):\n",
    "        \n",
    "        image_1_pooling_style = hp.Choice(f\"image_1_pooling_style_{i}\", ['max', 'average'], default='max')\n",
    "        image_2_pooling_style = hp.Choice(f\"image_2_pooling_style_{i}\", ['max', 'average'], default='max')\n",
    "        \n",
    "        a = hp.Float(f\"x_coefficient_{i}\", -4, 4)\n",
    "        b = hp.Float(f\"y_coefficient_{i}\", -4, 4)\n",
    "        c = hp.Float(f\"xy_coefficient_{i}\", -16, 16)\n",
    "        \n",
    "        if image_1_pooling_style == \"max\" and image_2_pooling_style == \"max\":\n",
    "            lambda_outputs.append(Lambda(lambda x : (a*x[0] + b*x[1])**2 + c*x[0]*x[1])([x1_max, x2_max]))\n",
    "        elif image_1_pooling_style == \"average\" and image_2_pooling_style == \"max\":\n",
    "            lambda_outputs.append(Lambda(lambda x : (a*x[0] + b*x[1])**2 + c*x[0]*x[1])([x1_avg, x2_max]))\n",
    "        elif image_1_pooling_style == \"average\" and image_2_pooling_style == \"average\":\n",
    "            lambda_outputs.append(Lambda(lambda x : (a*x[0] + b*x[1])**2 + c*x[0]*x[1])([x1_avg, x2_avg]))\n",
    "        elif image_1_pooling_style == \"max\" and image_2_pooling_style == \"average\":\n",
    "            lambda_outputs.append(Lambda(lambda x : (a*x[0] + b*x[1])**2 + c*x[0]*x[1])([x1_max, x2_avg]))\n",
    "        else:\n",
    "            raise ValueError(f'illegal pooling style {image_1_pooling_style} {image_2_pooling_style}')\n",
    "    \n",
    "    if len(lambda_outputs) > 1:\n",
    "        x = Concatenate(axis=-1)(lambda_outputs)\n",
    "    else:\n",
    "        x = lambda_outputs[0]\n",
    "        \n",
    "    activation_function = hp.Choice(f\"activation\", ['relu', 'softplus', 'softsign', 'elu', 'selu'], default='relu')\n",
    "    \n",
    "    for j in range(hp.Int(\"number_of_dense_final_layers\", 1, 2, default=1)):\n",
    "        x = Dense(units=hp.Int(f\"dense_final_unit_{j}\", 8, 256, default=128), kernel_constraint=max_norm(1.5), bias_constraint=max_norm(1.5), activation=activation_function)(x)\n",
    "        x = Dropout(hp.Float(f\"dropout_dense_final_unit_{j}\", 0, 0.36))(x)\n",
    "                                                                                             \n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = tf.keras.Model([input1, input2], out)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(hp.Float(\"lr\", 0.00000001, 0.001, sampling=\"log\")),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    input_1 = Input(shape=(224, 224, 3))\n",
    "    input_2 = Input(shape=(224, 224, 3))\n",
    "\n",
    "    base_model = VGGFace(model='resnet50', include_top=False)\n",
    "\n",
    "    for x in base_model.layers[:-3]:\n",
    "        x.trainable = True\n",
    "\n",
    "    x1 = base_model(input_1)\n",
    "    x2 = base_model(input_2)\n",
    "\n",
    "\n",
    "    x1=GlobalMaxPool2D()(x1)\n",
    "    x2=GlobalAvgPool2D()(x2)\n",
    "    \n",
    "    x3 = Subtract()([x1, x2])\n",
    "    x3 = Multiply()([x3, x3])\n",
    "\n",
    "    x1_ = Multiply()([x1, x1])\n",
    "    x2_ = Multiply()([x2, x2])\n",
    "    x4 = Subtract()([x1_, x2_])\n",
    "    \n",
    "    x5 = Multiply()([x1, x2])\n",
    "    \n",
    "    x = Concatenate(axis=-1)([x3, x4, x5])\n",
    "#     x = Dense(512, activation=\"relu\")(x)\n",
    "#     x = Dropout(0.03)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "\n",
    "    model = Model([input_1, input_2], out)\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00001))\n",
    "#     model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc'], optimizer=Adam(0.00003))\n",
    "#     model.compile(loss=[focal_loss(alpha=.25, gamma=2)], metrics=['acc'], optimizer=Adam(0.00001))\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bce51a863438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-4c35911418a9>\u001b[0m in \u001b[0;36mbaseline_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minput_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGGFace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resnet50'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/keras_vggface/vggface.py\u001b[0m in \u001b[0;36mVGGFace\u001b[0;34m(include_top, model, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 ' as true, `classes` should be 8631')\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         return RESNET50(include_top=include_top, input_tensor=input_tensor,\n\u001b[0m\u001b[1;32m     95\u001b[0m                         \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpooling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                         \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/keras_vggface/models.py\u001b[0m in \u001b[0;36mRESNET50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mbn_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     x = Conv2D(\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         name='conv1/7x7_s2')(img_input)\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2710\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2711\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2712\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    196\u001b[0m                                        self.filters)\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     self.kernel = self.add_weight(\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mcaching_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m     variable = self._add_variable_with_custom_getter(\n\u001b[0m\u001b[1;32m    624\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0;31m# \"best effort\" to set the initializer with the highest restore UID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m     new_variable = getter(\n\u001b[0m\u001b[1;32m    806\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    128\u001b[0m   \u001b[0;31m# can remove the V1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m   \u001b[0mvariable_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m   return tf_variables.VariableV1(\n\u001b[0m\u001b[1;32m    131\u001b[0m       \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maggregation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0maggregation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariableAggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     return previous_getter(\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                         shape=None):\n\u001b[1;32m    198\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2602\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m     \u001b[0mdistribute_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distribute_strategy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2604\u001b[0;31m     return resource_variable_ops.ResourceVariable(\n\u001b[0m\u001b[1;32m   2605\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1572\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1574\u001b[0;31m       self._init_from_args(\n\u001b[0m\u001b[1;32m   1575\u001b[0m           \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1710\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m       \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAdditional\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \"\"\"\n\u001b[0;32m--> 409\u001b[0;31m     return super(VarianceScaling, self).__call__(\n\u001b[0m\u001b[1;32m    410\u001b[0m         shape, dtype=_get_dtype(dtype), **kwargs)\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m     return op(\n\u001b[0m\u001b[1;32m   1082\u001b[0m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0mmaxval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"random_uniform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;31m# In case of [0,1) floating results, minval and maxval is unused. We do an\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;31m# `is` comparison here since this is cheaper than isinstance or  __eq__.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mshape_tensor\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m   1033\u001b[0m       \u001b[0;31m# not convertible to Tensors because of mixed content.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    265\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dl3/lib/python3.9/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_tfrt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m           \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ContextOptionsSetTfrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_tfrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mcontext_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "            train_gen, \n",
    "            use_multiprocessing=False,\n",
    "            validation_data=val_gen, \n",
    "            epochs=16, \n",
    "            steps_per_epoch=32, validation_steps=128\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image as image_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_gen = get_random_train_val_sets(relationship_set, non_relationship_set, k_folds, folder_to_images_map)\n",
    "for i, (train_gen, val_gen) in enumerate(train_val_gen):\n",
    "\n",
    "    tuner = kt.Hyperband(\n",
    "        build_model, \n",
    "        max_model_size=1000000000,\n",
    "        project_name=f'/media/roman/9C4210C14210A256/kinship_models_random_validation_new_{index}',\n",
    "        objective=\"val_accuracy\", \n",
    "        max_epochs=16, \n",
    "        hyperband_iterations=1,\n",
    "        overwrite=True,\n",
    "        executions_per_trial=3,\n",
    "    )\n",
    "\n",
    "    tuner.search(\n",
    "        train_gen, \n",
    "        validation_data=val_gen, \n",
    "        steps_per_epoch=128,\n",
    "        validation_steps=128,\n",
    "        callbacks=callbacks_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = []\n",
    "\n",
    "for j, _ in enumerate(train_val_generator):\n",
    "    tuner = kt.Hyperband(\n",
    "        build_model, \n",
    "        max_model_size=1000000000,\n",
    "        project_name=f'/media/roman/9C4210C14210A256/kinship_models_random_validation_{index}',\n",
    "        objective=\"val_accuracy\", \n",
    "        max_epochs=36, \n",
    "        hyperband_iterations=1,\n",
    "        overwrite=False,\n",
    "        executions_per_trial=4,\n",
    "    )\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=8)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(0, len(submission.p1.values), 32):\n",
    "\n",
    "        X1 = submission.p1.values[i:i+32]\n",
    "        X1 = np.array([read_img(test_path + x) for x in X1])\n",
    "\n",
    "        X2 = submission.p2.values[i:i+32]\n",
    "        X2 = np.array([read_img(test_path + x) for x in X2])\n",
    "\n",
    "        pred = model.predict([X1, X2]).ravel().tolist()\n",
    "        predictions += pred\n",
    "        \n",
    "    np.array(predictions)\n",
    "        \n",
    "    prediction_list.append(predictions)\n",
    "    \n",
    "    d = {'index': np.arange(0, 3000, 1), 'label': predictions}\n",
    "    submissionfile = pd.DataFrame(data=d)\n",
    "    submissionfile = submissionfile.round()\n",
    "    submissionfile['label'] = submissionfile['label'].astype(int)\n",
    "    submissionfile.to_csv(f\"/home/roman/Work/kinship/jba2131_rzw2002_pwc_random_validation_ensemble_v2_{datetime.date.today().strftime('%Y_%m_%d')}_{j}.csv\", index=False)\n",
    "\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/home/roman/Work/kinship/test_ds.csv')\n",
    "test_path = \"./test/\"\n",
    "prediction_list = []\n",
    "\n",
    "train_val_generator = get_train_validation_sets_from_split(validation_sets)\n",
    "\n",
    "for index, (train, val, train_map, val_map) in enumerate(train_val_generator):\n",
    "    tuner = kt.Hyperband(\n",
    "        build_model, \n",
    "        max_model_size=1000000000,\n",
    "        project_name=f'/media/roman/9C4210C14210A256/kinship_models_random_validation_{index}',\n",
    "        objective=\"val_accuracy\", \n",
    "        max_epochs=36, \n",
    "        hyperband_iterations=1,\n",
    "        overwrite=False,\n",
    "        executions_per_trial=4,\n",
    "    )\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=8)\n",
    "    for hps in best_hps:\n",
    "        model = tuner.hypermodel.build(hps)\n",
    "        submission = pd.read_csv('/home/roman/Work/kinship/test_ds.csv')\n",
    "        predictions = []\n",
    "        for i in range(0, len(submission.p1.values), 32):\n",
    "\n",
    "            X1 = submission.p1.values[i:i+32]\n",
    "            X1 = np.array([read_img(test_path + x) for x in X1])\n",
    "\n",
    "            X2 = submission.p2.values[i:i+32]\n",
    "            X2 = np.array([read_img(test_path + x) for x in X2])\n",
    "\n",
    "            pred = model.predict([X1, X2]).ravel().tolist()\n",
    "            predictions += pred\n",
    "#         d = {'index': np.arange(0, 3000, 1), 'label': predictions}\n",
    "#         submissionfile = pd.DataFrame(data=d)\n",
    "#         submissionfile = submissionfile.round()\n",
    "#         submissionfile['label'] = submissionfile['label'].astype(int)\n",
    "#         submissionfile.to_csv(f\"/home/roman/Work/kinship/jba2131_rzw2002_pwc_random_validation_ensemble_v2_{datetime.date.today().strftime('%Y_%m_%d')\n",
    "        prediction_list.append(predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('giant_ensemble_set.pickle', 'wb') as f:\n",
    "    pickle.dump(prediction_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "func = lambda x: int(round(x,0))\n",
    "final_predictions = [list(map(func, i)) for i in prediction_list]\n",
    "final_predictions = stats.mode(final_predictions[:39])[0][0]\n",
    "d = {'index': np.arange(0, 3000, 1), 'label': final_predictions}\n",
    "submissionfile = pd.DataFrame(data=d)\n",
    "submissionfile['label'] = submissionfile['label'].astype(int)\n",
    "submissionfile.to_csv(f\"/home/roman/Work/kinship/jba2131_rzw2002_automl_mega_ensemble_v1_{datetime.date.today().strftime('%Y_%m_%d')}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle competitions submit -c coms4995-kinship-recognition -f /home/roman/Work/kinship/jba2131_rzw2002_automl_mega_ensemble_v1_2021_08_11.csv -m \"automl mega ensemble v1 first 39\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl3",
   "language": "python",
   "name": "dl3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
